# Copilot活用時の注意点一覧（AIの特性に基づく）

このドキュメントは、GitHub CopilotなどのAI補完ツールを開発業務に活用する際に留意すべき特性と、注意点をまとめたものです。  
AIの「強み」と「落とし穴」を理解した上で、チーム全体の品質と効率を高めることを目的とします。

---

## 🔍 Copilotの特性と注意点

| 項目 | AIの動作特性 | 注意点（人間の対応） |
|------|----------------|------------------------|
| **曖昧な仕様** | 文脈や類似パターンから**推測補完**する | 必ず**仕様を明文化・確認**し、出力の意図をレビューする |
| **過去コードの模倣** | 既存コードや典型的パターンをそのまま再利用 | プロジェクト独自の設計・命名規約と**ズレがないか確認** |
| **自信過剰な補完** | 正誤に関わらず、自然に見える出力を行う | **テスト・型・責務分離で裏をとる**。出力に過信しない |
| **型安全性** | コンパイル通過レベルで整形される | **非nullチェックや例外処理の有無を人間が担保**する |
| **ステートレス生成** | 過去の出力と整合性を取らないことがある | 同一メソッド名の一貫性などは**人間が意識的に管理**する |
| **依存解決の甘さ** | 自動生成において依存モジュールの挙動を省略 | **外部ライブラリや契約インターフェースの確認を徹底**する |
| **意味のない名前付け** | 変数やメソッド名が機械的（temp, helperなど） | **ドメイン・ユースケースに即した命名に書き直すこと** |
| **非対話的生成** | 推測が中心で「これは正しいですか？」とは聞かない | 生成内容が怪しい場合は**自分で意図を言語化し直す** |

---

## 🧠 設計フェーズでのCopilot活用の心得

1. **AIに“仕様の穴”を炙り出させる**  
   → わざと仕様が不十分な状態で入力し、Copilotの補完で「想定外の動き」を発見する。

2. **前提情報を先に宣言する**  
   → “この変数はnullにならない”“リトライ制御は別レイヤーで行う”等、暗黙知を明文化すると補完精度が上がる。

3. **複数案を並べて比較させる**  
   → 「こう書く方法もある」といったバリエーション提案を受け、最適解を人間が選ぶ。

4. **AIを“先行プロトタイパ”として使う**  
   → あくまで仮の案生成として使い、あとでアーキテクトやレビュアーの確認を前提とする。

---

## ✅ 最後に：Copilotの出力は「提案」であり、「決定」ではない

- コードを書く速度は上がるが、**設計の責任は人間にある**
- **疑う目・チェックする目がある限り、AIは最高の補助輪になる**

